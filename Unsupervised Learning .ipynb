{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d79cd0-aa27-4670-9605-b463ca587f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score,\n",
    "    davies_bouldin_score,\n",
    "    calinski_harabasz_score,\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    homogeneity_completeness_v_measure,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abf6e6-0856-4f32-a01b-115428848b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(X, clusters, y_true=None, label_names=None):\n",
    "    \"\"\"\n",
    "    X: array-like (n_samples, n_features) - usually scaled/PCA output used for clustering\n",
    "    clusters: array-like (n_samples,) - predicted cluster id for each sample\n",
    "    y_true: array-like (n_samples,) or None - optional true labels (e.g., genre_label) for external eval\n",
    "    label_names: list[str] or None - optional class names aligned with y_true encoding (e.g., le.classes_)\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # ---- Internal / unsupervised metrics ----\n",
    "    # Note: silhouette requires at least 2 clusters and no all-same labels.\n",
    "    unique_clusters = np.unique(clusters)\n",
    "    if len(unique_clusters) > 1 and not np.all(clusters == clusters[0]):\n",
    "        results[\"silhouette\"] = silhouette_score(X, clusters)\n",
    "    else:\n",
    "        results[\"silhouette\"] = np.nan\n",
    "\n",
    "    # Davies-Bouldin and Calinski-Harabasz also require >1 cluster\n",
    "    if len(unique_clusters) > 1:\n",
    "        results[\"davies_bouldin\"] = davies_bouldin_score(X, clusters)\n",
    "        results[\"calinski_harabasz\"] = calinski_harabasz_score(X, clusters)\n",
    "    else:\n",
    "        results[\"davies_bouldin\"] = np.nan\n",
    "        results[\"calinski_harabasz\"] = np.nan\n",
    "\n",
    "    # ---- External / label-based metrics (optional) ----\n",
    "    if y_true is not None:\n",
    "        results[\"ARI\"] = adjusted_rand_score(y_true, clusters)\n",
    "        results[\"NMI\"] = normalized_mutual_info_score(y_true, clusters)\n",
    "        h, c, v = homogeneity_completeness_v_measure(y_true, clusters)\n",
    "        results[\"homogeneity\"] = h\n",
    "        results[\"completeness\"] = c\n",
    "        results[\"v_measure\"] = v\n",
    "\n",
    "        # Confusion-like matrix: rows=true genre, cols=cluster\n",
    "        cm = confusion_matrix(y_true, clusters)\n",
    "        cm_df = pd.DataFrame(\n",
    "            cm,\n",
    "            index=label_names if label_names is not None else [f\"genre_{i}\" for i in np.unique(y_true)],\n",
    "            columns=[f\"cluster_{c}\" for c in np.unique(clusters)]\n",
    "        )\n",
    "\n",
    "        # Cluster -> majority genre mapping (interpretable)\n",
    "        tmp = pd.DataFrame({\"y_true\": y_true, \"cluster\": clusters})\n",
    "        cluster_to_majority_label = (\n",
    "            tmp.groupby(\"cluster\")[\"y_true\"]\n",
    "               .agg(lambda s: s.value_counts().idxmax())\n",
    "        )\n",
    "\n",
    "        if label_names is not None:\n",
    "            cluster_to_majority_name = cluster_to_majority_label.map(lambda k: label_names[k])\n",
    "        else:\n",
    "            cluster_to_majority_name = cluster_to_majority_label\n",
    "\n",
    "        return results, cm_df, cluster_to_majority_name\n",
    "\n",
    "    return results, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4550757-2d07-4dc1-88a7-bbe614079613",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\zuhai\\Desktop\\Projects\\Machine Learning Project\\songs_data.csv\")\n",
    "le = LabelEncoder()\n",
    "df[\"genre_label\"] = le.fit_transform(df[\"genre\"])\n",
    "\n",
    "# Optional: see the mapping\n",
    "genre_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Genre mapping:\", genre_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44b6ee-279d-4cc1-940b-cd744f75855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = [\n",
    "    \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\",\n",
    "    \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\",\n",
    "    \"tempo\", \"duration_ms\"\n",
    "]\n",
    "\n",
    "# Keep a clean copy with needed cols (genre kept ONLY for post-hoc inspection)\n",
    "cols_to_keep = audio_features + ([\"genre\"] if \"genre\" in df.columns else [])\n",
    "df_clean = df[cols_to_keep].dropna().reset_index(drop=True)\n",
    "\n",
    "X = df_clean[audio_features].values  # <-- no genre here\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Scale + PCA (recommended)\n",
    "# ----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Keep 90% variance; you can change to n_components=2 for easy plotting\n",
    "pca = PCA(n_components=0.90, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3) Choose K WITHOUT using genre labels (silhouette search)\n",
    "# ---------------------------------------------------------\n",
    "def choose_best_k(X_embedded, k_min=2, k_max=10, random_state=42):\n",
    "    best_k, best_score = None, -1\n",
    "    scores = {}\n",
    "\n",
    "    for k in range(k_min, k_max + 1):\n",
    "        km = KMeans(n_clusters=k, random_state=random_state, n_init=\"auto\")\n",
    "        labels = km.fit_predict(X_embedded)\n",
    "\n",
    "        # silhouette needs at least 2 clusters and no singleton-only issues\n",
    "        score = silhouette_score(X_embedded, labels)\n",
    "        scores[k] = score\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    return best_k, scores\n",
    "\n",
    "\n",
    "best_k, sil_scores = choose_best_k(X_pca, k_min=2, k_max=10)\n",
    "print(\"Silhouette scores by K:\", sil_scores)\n",
    "print(\"Best K selected (by silhouette):\", best_k)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) K-Means clustering\n",
    "# ----------------------------\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=\"auto\")\n",
    "kmeans_labels = kmeans.fit_predict(X_pca)\n",
    "df_clean[\"kmeans_cluster\"] = kmeans_labels\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Hierarchical clustering\n",
    "# ----------------------------\n",
    "# Ward linkage works well with Euclidean distance on scaled/PCA data\n",
    "hier = AgglomerativeClustering(n_clusters=best_k, linkage=\"ward\")\n",
    "hier_labels = hier.fit_predict(X_pca)\n",
    "df_clean[\"hier_cluster\"] = hier_labels\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6) Internal (label-free) cluster evaluation\n",
    "# ---------------------------------------------\n",
    "def internal_metrics(X_embedded, labels, name=\"model\"):\n",
    "    uniq = np.unique(labels)\n",
    "    if len(uniq) < 2:\n",
    "        return {\n",
    "            \"model\": name,\n",
    "            \"silhouette\": np.nan,\n",
    "            \"davies_bouldin\": np.nan,\n",
    "            \"calinski_harabasz\": np.nan,\n",
    "            \"n_clusters\": len(uniq)\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"silhouette\": silhouette_score(X_embedded, labels),\n",
    "        \"davies_bouldin\": davies_bouldin_score(X_embedded, labels),\n",
    "        \"calinski_harabasz\": calinski_harabasz_score(X_embedded, labels),\n",
    "        \"n_clusters\": len(uniq)\n",
    "    }\n",
    "\n",
    "\n",
    "kmeans_metrics = internal_metrics(X_pca, kmeans_labels, \"KMeans\")\n",
    "hier_metrics = internal_metrics(X_pca, hier_labels, \"Hierarchical\")\n",
    "\n",
    "metrics_df = pd.DataFrame([kmeans_metrics, hier_metrics])\n",
    "print(\"\\nInternal evaluation (no genre used):\")\n",
    "print(metrics_df)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 7) Post-hoc investigation: Are clusters \"meaningful\" w.r.t. genre?\n",
    "#     (This does NOT affect training; it is just analysis.)\n",
    "# --------------------------------------------------------------------\n",
    "if \"genre\" in df_clean.columns:\n",
    "    # (a) Genre distribution per cluster (normalized)\n",
    "    kmeans_genre_dist = (\n",
    "        df_clean.groupby(\"kmeans_cluster\")[\"genre\"]\n",
    "                .value_counts(normalize=True)\n",
    "                .unstack(fill_value=0)\n",
    "                .round(3)\n",
    "    )\n",
    "\n",
    "    hier_genre_dist = (\n",
    "        df_clean.groupby(\"hier_cluster\")[\"genre\"]\n",
    "                .value_counts(normalize=True)\n",
    "                .unstack(fill_value=0)\n",
    "                .round(3)\n",
    "    )\n",
    "\n",
    "    print(\"\\nK-Means: cluster -> genre distribution (normalized):\")\n",
    "    print(kmeans_genre_dist)\n",
    "\n",
    "    print(\"\\nHierarchical: cluster -> genre distribution (normalized):\")\n",
    "    print(hier_genre_dist)\n",
    "\n",
    "    # (b) Majority-genre label per cluster (easy interpretation)\n",
    "    kmeans_majority = (\n",
    "        df_clean.groupby(\"kmeans_cluster\")[\"genre\"]\n",
    "                .agg(lambda s: s.value_counts().idxmax())\n",
    "    )\n",
    "\n",
    "    hier_majority = (\n",
    "        df_clean.groupby(\"hier_cluster\")[\"genre\"]\n",
    "                .agg(lambda s: s.value_counts().idxmax())\n",
    "    )\n",
    "\n",
    "    print(\"\\nK-Means: cluster -> majority genre\")\n",
    "    print(kmeans_majority)\n",
    "\n",
    "    print(\"\\nHierarchical: cluster -> majority genre\")\n",
    "    print(hier_majority)\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8) Interpret clusters by mean audio feature values\n",
    "# -------------------------------------------------\n",
    "kmeans_feature_means = df_clean.groupby(\"kmeans_cluster\")[audio_features].mean().round(3)\n",
    "hier_feature_means = df_clean.groupby(\"hier_cluster\")[audio_features].mean().round(3)\n",
    "\n",
    "print(\"\\nK-Means: mean audio features per cluster\")\n",
    "print(kmeans_feature_means)\n",
    "\n",
    "print(\"\\nHierarchical: mean audio features per cluster\")\n",
    "print(hier_feature_means)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 9) Optional: quick PCA plot\n",
    "# ----------------------------\n",
    "# If you want a visual scatter plot:\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure()\n",
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, s=10)\n",
    "# plt.title(\"K-Means Clusters (PCA space)\")\n",
    "# plt.xlabel(\"PC1\")\n",
    "# plt.ylabel(\"PC2\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
